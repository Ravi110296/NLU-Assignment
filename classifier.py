# -*- coding: utf-8 -*-
"""Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RjKd606q-Ceri0YeuEW15z5zoy7GvT0f
"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

# Read data from files
def read_file(file_name):
    with open(file_name, "r", encoding="utf-8") as f:
        lines = f.readlines()
    return [line.strip() for line in lines]  # Stripping newlines

# Load the data
sports = read_file("sports.txt")
politics = read_file("politics.txt")

all_texts = sports + politics
labels_list = ["sport"] * len(sports) + ["politics"] * len(politics)  # Labels

# Split the data, using random_state=42
train_X, test_X, train_y, test_y = train_test_split(
    all_texts, labels_list, test_size=0.2, random_state=42
)

# TF-IDF vectorizer, ngrams 1-2 used
vec = TfidfVectorizer(ngram_range=(1,2))
train_vec = vec.fit_transform(train_X)
test_vec = vec.transform(test_X)

# Models to try
nb_model = MultinomialNB()
lr_model = LogisticRegression(max_iter=1000)
svm = LinearSVC()

model_dict = {  # Dict for models
    "Naive Bayes": nb_model,
    "Log Reg": lr_model,
    "SVM": svm
}

for model_name, model in model_dict.items():
    model.fit(train_vec, train_y)
    preds = model.predict(test_vec)
    accuracy = accuracy_score(test_y, preds)
    print(model_name + " "+"accuracy:", round(accuracy * 100, 2), "%")  # Added + for string

# Choose best model (SVM)
best_model = svm
best_model.fit(train_vec, train_y)

print("\nType a sentence to classify (or 'exit' to stop):")

while True:
    user_input = input("You: ")
    
    if user_input.lower() == "exit":
        break
    
    # Vectorize user input
    user_vector = vec.transform([user_input])
    pred = best_model.predict(user_vector)
    
    print(pred[0])
